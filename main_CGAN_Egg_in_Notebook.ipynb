{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# some basics\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from progress.bar import IncrementalBar\n",
    "\n",
    "\n",
    "# unconditonal Conditional GAN \n",
    "from gan.utils import reset_random_seeds\n",
    "from cgan.generator import UnetGenerator\n",
    "from cgan.discriminator import ConditionalDiscriminator\n",
    "from cgan.criterion import GeneratorLoss, DiscriminatorLoss\n",
    "from cgan.utils import Logger\n",
    "\n",
    "# for visualization 3d model\n",
    "from visual_3d import visual_3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seed\n",
    "reset_random_seeds(77777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import training data - 100 channel facies model\n",
    "ensemble_facies = np.load('Ensemble_facies.npy')\n",
    "ensemble_perm = np.load('Ensemble.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1,2,1)\n",
    "plt.imshow(ensemble_facies[0,0])\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(ensemble_perm[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visual_3d(ensemble_facies[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess data\n",
    "ensemble_facies_pad = np.zeros((100, 8, 64, 64))\n",
    "ensemble_perm_pad = np.zeros((100, 8, 64, 64))\n",
    "\n",
    "for i in range(100):\n",
    "    ensemble_perm_pad[i] = np.pad(ensemble_perm[i], ((0, 1), (2, 2), (2, 2)), 'reflect')\n",
    "    ensemble_facies_pad[i] = np.pad(ensemble_facies[i], ((0, 1), (2, 2), (2, 2)), 'reflect')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper-parameters\n",
    "LEARNING_RATE = 0.0002\n",
    "BATCH_SIZE = 25\n",
    "EPOCHS = 501\n",
    "EXP_NAME = './conditioanl_gan_run02_alpha_1'\n",
    "LOG_FILENAME = 'training_log'\n",
    "\n",
    "# rescale training data from -1 to 1\n",
    "ensemble_facies_scaled = ensemble_facies_pad * 2 - 1\n",
    "ensemble_log_perm_pad = np.log(ensemble_perm_pad)\n",
    "ensemble_log_perm_pad[ensemble_log_perm_pad<4] = 4\n",
    "ensemble_log_perm_min, ensemble_log_perm_max = ensemble_log_perm_pad.min(), ensemble_log_perm_pad.max()\n",
    "ensemble_log_perm_sacled = (ensemble_log_perm_pad - ensemble_log_perm_min)/(ensemble_log_perm_max- ensemble_log_perm_min)*2 -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "total_num_of_data = ensemble_facies_scaled.shape[0]\n",
    "inputs  = torch.tensor(ensemble_facies_scaled.astype(np.float32).reshape(total_num_of_data, 1, 8, 64, 64))\n",
    "targets = torch.tensor(ensemble_log_perm_sacled.astype(np.float32).reshape(total_num_of_data, 1, 8, 64, 64))\n",
    "dataset = TensorDataset(targets, inputs)\n",
    "data_loader = DataLoader(dataset, BATCH_SIZE, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(1)\n",
    "print(f\"Using GPU: {torch.cuda.current_device()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Instantiate models\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "generator = UnetGenerator().to(device)\n",
    "discriminator = ConditionalDiscriminator().to(device)\n",
    "\n",
    "## define optimizer and loss\n",
    "# optimizers\n",
    "g_optimizer = torch.optim.Adam(generator.parameters(), lr=LEARNING_RATE, betas=(0.5, 0.999))\n",
    "d_optimizer = torch.optim.Adam(discriminator.parameters(), lr=LEARNING_RATE, betas=(0.5, 0.999))\n",
    "# loss functions\n",
    "g_criterion = GeneratorLoss(alpha=10)\n",
    "d_criterion = DiscriminatorLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Start of training process!')\n",
    "logger = Logger(exp_name = EXP_NAME, filename= LOG_FILENAME)\n",
    "for epoch in range(EPOCHS):\n",
    "    ge_loss=0.\n",
    "    de_loss=0.\n",
    "    start = time.time()\n",
    "    bar = IncrementalBar(f'[Epoch {epoch+1}/{EPOCHS}]', max=len(data_loader))\n",
    "    for x, real in data_loader:\n",
    "        x = x.to(device)\n",
    "        real = real.to(device)\n",
    "\n",
    "        # Generator`s loss\n",
    "        fake = generator(x)\n",
    "        fake_pred = discriminator(fake, x)\n",
    "        g_loss = g_criterion(fake, real, fake_pred)\n",
    "\n",
    "        # Discriminator`s loss\n",
    "        fake = generator(x).detach()\n",
    "        fake_pred = discriminator(fake, x)\n",
    "        real_pred = discriminator(real, x)\n",
    "        d_loss = d_criterion(fake_pred, real_pred)\n",
    "\n",
    "        # Generator`s params update\n",
    "        g_optimizer.zero_grad()\n",
    "        g_loss.backward()\n",
    "        g_optimizer.step()\n",
    "\n",
    "        # Discriminator`s params update\n",
    "        d_optimizer.zero_grad()\n",
    "        d_loss.backward()\n",
    "        d_optimizer.step()\n",
    "        # add batch losses\n",
    "        ge_loss += g_loss.item()\n",
    "        de_loss += d_loss.item()\n",
    "        bar.next()\n",
    "    bar.finish()  \n",
    "    # obttain per epoch losses\n",
    "    g_loss = ge_loss/len(data_loader)\n",
    "    d_loss = de_loss/len(data_loader)\n",
    "    # count timeframe\n",
    "    end = time.time()\n",
    "    tm = (end - start)\n",
    "    logger.add_scalar('generator_loss', g_loss, epoch+1)\n",
    "    logger.add_scalar('discriminator_loss', d_loss, epoch+1)\n",
    "    if epoch % 250 == 0:\n",
    "        logger.save_weights(generator.state_dict(), f'generator_{epoch}')\n",
    "        logger.save_weights(discriminator.state_dict(), f'generator_{epoch}')\n",
    "    print(\"[Epoch %d/%d] [G loss: %.3f] [D loss: %.3f] ETA: %.3fs\" % (epoch+1, EPOCHS, g_loss, d_loss, tm))\n",
    "    if epoch % 10 == 0:\n",
    "        plt.figure(figsize = (10,10))\n",
    "        fake = generator(x).detach().cpu().numpy().squeeze()\n",
    "        for i_subplot in range(9):\n",
    "            plt.subplot(3,3,i_subplot+1)\n",
    "            plt.imshow(fake[i_subplot,0])\n",
    "        plt.savefig(os.path.join(EXP_NAME,f\"outcomes_epoch_{epoch:05}.pdf\"))\n",
    "        plt.close()\n",
    "        \n",
    "        plt.figure(figsize = (10,10))\n",
    "        real = real.detach().cpu().numpy().squeeze()\n",
    "        for i_subplot in range(9):\n",
    "            plt.subplot(3,3,i_subplot+1)\n",
    "            plt.imshow(real[i_subplot,0])\n",
    "        plt.savefig(os.path.join(EXP_NAME,f\"outcomes_epoch_{epoch:05}_ans.pdf\"))\n",
    "        plt.close()\n",
    "logger.close()\n",
    "print('End of training process!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(0)\n",
    "\n",
    "inputs  = torch.tensor(ensemble_facies_scaled.astype(np.float32).reshape(total_num_of_data, 1, 8, 64, 64)).to(device)\n",
    "targets = torch.tensor(ensemble_log_perm_sacled.astype(np.float32).reshape(total_num_of_data, 1, 8, 64, 64)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(0)\n",
    "generator = generator.to(device)\n",
    "fake = generator(inputs[:10]).detach().cpu().numpy().squeeze()\n",
    "input_real = inputs[:10].detach().cpu().numpy().squeeze()\n",
    "real = targets[:10].detach().cpu().numpy().squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,10))\n",
    "for i in range(3):\n",
    "    plt.subplot(3,3,3*i+1)\n",
    "    plt.title(f'Real Image - {i}')\n",
    "    plt.imshow(input_real[i][0])\n",
    "\n",
    "    plt.subplot(3,3,3*i+2)\n",
    "    plt.title(f'Observation - {i}')\n",
    "    plt.imshow(real[i][0])\n",
    "\n",
    "    \n",
    "    plt.subplot(3,3,3*i+3)\n",
    "    plt.title(f'Generated Image - {i}')\n",
    "    plt.imshow(fake[i][0]>0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
